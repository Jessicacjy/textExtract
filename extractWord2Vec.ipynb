{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import sys\n",
    "print(\"extract1\")\n",
    "try:\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from snownlp import SnowNLP\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "DATA_SWAP = \"/Users/daichanglin/Desktop/igoldenbeta/python/temp.txt\";\n",
    "DATA_SWAP2 = \"/Users/daichanglin/Desktop/igoldenbeta/python/temp2.txt\";\n",
    "#load model\n",
    "model = Word2Vec.load('/Users/Jesica/Documents/igolden/word2vec/word2vec-tutorial-master/w2v100.model.bin')\n",
    "\n",
    "def extract():\n",
    "    print(\"extract2\")\n",
    "    try:\n",
    "        f = codecs.open(DATA_SWAP, 'r','utf-8')\n",
    "        w = codecs.open(DATA_SWAP2, 'w','utf-8') # 若是'wb'就表示写二进制文件\n",
    "        all_the_text = f.read()\n",
    "        # print(all_the_text.decode('utf-8'))\n",
    "        ret = extractSummary(all_the_text)\n",
    "        # print(ret.encode('gbk'))\n",
    "        for x in ret:\n",
    "            # print(x.decode('utf-8'))\n",
    "            w.write(x+'\\r\\n')\n",
    "    finally:\n",
    "        if f:\n",
    "            f.close()\n",
    "        if w:\n",
    "            w.close()\n",
    "\n",
    "def cut_sentences(sentence):  \n",
    "    puns = frozenset(u'。！？')  \n",
    "    tmp = []  \n",
    "    for ch in sentence:  \n",
    "        tmp.append(ch)  \n",
    "        if puns.__contains__(ch):  \n",
    "            yield ''.join(tmp)  \n",
    "            tmp = []  \n",
    "    yield ''.join(tmp)\n",
    "    \n",
    "def two_sentences_similarity(sents_1, sents_2):  \n",
    "    ''''' \n",
    "    计算两个句子的相似性 \n",
    "    相同词语的百分比\n",
    "    :param sents_1: \n",
    "    :param sents_2: \n",
    "    :return: \n",
    "    '''  \n",
    "    counter = 0  \n",
    "    for sent in sents_1:  \n",
    "        if sent in sents_2:  \n",
    "            counter += 1  \n",
    "    return counter / (math.log(len(sents_1) + len(sents_2)))  \n",
    "\n",
    "def create_graph(word_sent):  \n",
    "    \"\"\" \n",
    "    传入句子链表  返回句子之间相似度的图 \n",
    "    :param word_sent: \n",
    "    :return: \n",
    "    \"\"\"  \n",
    "    num = len(word_sent)  \n",
    "    board = [[0.0 for _ in range(num)] for _ in range(num)]  \n",
    "  \n",
    "    for i, j in product(range(num), repeat=2):  \n",
    "        if i != j:  \n",
    "            \n",
    "            board[i][j] = compute_similarity_by_avg(word_sent[i], word_sent[j])  \n",
    "    return board  \n",
    "  \n",
    "def cosine_similarity(vec1, vec2):  \n",
    "    ''''' \n",
    "    计算两个向量之间的余弦相似度 \n",
    "    :param vec1: \n",
    "    :param vec2: \n",
    "    :return: \n",
    "    '''  \n",
    "    tx = np.array(vec1)  \n",
    "    ty = np.array(vec2)  \n",
    "    cos1 = np.sum(tx * ty)  \n",
    "    cos21 = np.sqrt(sum(tx ** 2))  \n",
    "    cos22 = np.sqrt(sum(ty ** 2))  \n",
    "    cosine_value = cos1 / float(cos21 * cos22)  \n",
    "    return cosine_value  \n",
    "\n",
    "def compute_similarity_by_avg(sents_1, sents_2):  \n",
    "    ''''' \n",
    "    对两个句子求平均词向量 \n",
    "    :param sents_1: \n",
    "    :param sents_2: \n",
    "    :return: \n",
    "    '''  \n",
    "    if len(sents_1) == 0 or len(sents_2) == 0:  \n",
    "        return 0.0  \n",
    "    vec1 = model[sents_1[0]]  \n",
    "    for word1 in sents_1[1:]:  \n",
    "        vec1 = vec1 + model[word1]  \n",
    "  \n",
    "    vec2 = model[sents_2[0]]  \n",
    "    for word2 in sents_2[1:]:  \n",
    "        print\n",
    "        vec2 = vec2 + model[word2]  \n",
    "  \n",
    "    similarity = cosine_similarity(vec1 / len(sents_1), vec2 / len(sents_2))  \n",
    "    return similarity  \n",
    "  \n",
    "def calculate_score(weight_graph, scores, i):  \n",
    "    \"\"\" \n",
    "    计算句子在图中的分数 \n",
    "    :param weight_graph: \n",
    "    :param scores: \n",
    "    :param i: \n",
    "    :return: \n",
    "    \"\"\"  \n",
    "    length = len(weight_graph)  \n",
    "    d = 0.85  \n",
    "    added_score = 0.0  \n",
    "  \n",
    "    for j in range(length):  \n",
    "        fraction = 0.0  \n",
    "        denominator = 0.0  \n",
    "        # 计算分子  \n",
    "        fraction = weight_graph[j][i] * scores[j]  \n",
    "        # 计算分母  \n",
    "        for k in range(length):  \n",
    "            denominator += weight_graph[j][k]  \n",
    "            if denominator == 0:  \n",
    "                denominator = 1  \n",
    "        added_score += fraction / denominator  \n",
    "    # 算出最终的分数  \n",
    "    weighted_score = (1 - d) + d * added_score  \n",
    "    return weighted_score  \n",
    "\n",
    "def weight_sentences_rank(weight_graph):  \n",
    "    ''''' \n",
    "    输入相似度的图（矩阵) \n",
    "    返回各个句子的分数 \n",
    "    :param weight_graph: \n",
    "    :return: \n",
    "    '''  \n",
    "    # 初始分数设置为0.5  \n",
    "    scores = [0.5 for _ in range(len(weight_graph))]  \n",
    "    old_scores = [0.0 for _ in range(len(weight_graph))]  \n",
    "  \n",
    "    # 开始迭代  \n",
    "    while different(scores, old_scores):  \n",
    "        for i in range(len(weight_graph)):  \n",
    "            old_scores[i] = scores[i]  \n",
    "        for i in range(len(weight_graph)):  \n",
    "            scores[i] = calculate_score(weight_graph, scores, i)  \n",
    "    return scores  \n",
    "\n",
    "def different(scores, old_scores):  \n",
    "    ''''' \n",
    "    判断前后分数有无变化 \n",
    "    :param scores: \n",
    "    :param old_scores: \n",
    "    :return: \n",
    "    '''  \n",
    "    flag = False  \n",
    "    for i in range(len(scores)):  \n",
    "        if math.fabs(scores[i] - old_scores[i]) >= 0.0001:  \n",
    "            flag = True  \n",
    "            break  \n",
    "    return flag \n",
    "\n",
    "def filter_symbols(sents):  \n",
    "    stopwords = list(stopwordset)+ ['。', ' ', '.',', ','印']  \n",
    "    _sents = []  \n",
    "    for sentence in sents:  \n",
    "        _sent = []\n",
    "        for word in sentence:  \n",
    "            if word not in stopwordset:  \n",
    "                _sent.append(word)\n",
    "        if _sent:  \n",
    "            _sents.append(_sent)  \n",
    "    return _sents  \n",
    "def filter_model(sents):  \n",
    "    _sents = []  \n",
    "    for sentence in sents:  \n",
    "        _sent = []\n",
    "        for word in sentence:  \n",
    "            if word in model: \n",
    "                _sent.append(word) \n",
    "\n",
    "        if _sent:  \n",
    "            _sents.append(_sent)  \n",
    "    return _sents  \n",
    "\n",
    "def extractSummary(text, n=0):  \n",
    "    text = text.replace('\\n','')\n",
    "    tokens = cut_sentences(text) \n",
    "    s_count = 0\n",
    "    sentences = []  \n",
    "    sents = []  \n",
    "    ratio = 0.1 #取文本10%\n",
    "    for sent in tokens:  \n",
    "        s_count = s_count + 1\n",
    "        sentences.append(sent)  \n",
    "        sents.append([word for word in jieba.cut(sent) if word ])  \n",
    "#    print(sents)\n",
    "    sents_fs = filter_symbols(sents)  \n",
    "\n",
    "    sents_fm = filter_model(sents_fs)  \n",
    "    graph = create_graph(sents_fm)  \n",
    "    if n==0:\n",
    "        n = math.floor(s_count*ratio)\n",
    "\n",
    "    scores = weight_sentences_rank(graph)  \n",
    "    sent_selected = nlargest(n, zip(scores, count()))  \n",
    "    sent_index = []  \n",
    "\n",
    "    for i in range(n):  \n",
    "        sent_index.append(sent_selected[i][1])  \n",
    "    #return [sentences[i] for i in sent_index]  \n",
    "    return [(sentences[i]) for i in sent_index] \n",
    "\n",
    "\n",
    "def test(string1,string2):\n",
    "    return string1+string2\n",
    "\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "extract()\n",
    "\n",
    "# if __name__=='__main__':\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flint]",
   "language": "python",
   "name": "conda-env-flint-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
